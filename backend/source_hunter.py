from googlesearch import search
from urllib.parse import urlparse
import time

def find_implicit_sources(claim_data):
    """
    For claims without explicit links, try to find the original source
    using the search query generated by LLM
    """
    
    if claim_data.get('has_explicit_link', False):
        return []
    
    query = claim_data.get('search_query')
    if not query:
        return []
        
    # Search for the source
    potential_sources = []
    try:
        # Note: googlesearch-python might pause to avoid rate limits
        for url in search(query, num_results=5, sleep_interval=2):
            # Filter for authoritative domains
            if is_authoritative_domain(url):
                potential_sources.append({
                    'url': url,
                    'search_query': query,
                    'confidence': calculate_relevance(url, claim_data),
                    'type': 'discovered'
                })
    except Exception as e:
        print(f"Search failed: {e}")
    
    return potential_sources[:3]  # Top 3 results

def is_authoritative_domain(url):
    """Check if domain is typically authoritative"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        # High-authority TLDs
        if domain.endswith(('.gov', '.edu', '.org')):
            return True
        
        # Known authoritative sources (can be expanded)
        authoritative = [
            'nih.gov', 'cdc.gov', 'who.int', 'nature.com', 'science.org',
            'nytimes.com', 'washingtonpost.com', 'reuters.com', 'apnews.com',
            'jstor.org', 'arxiv.org', 'pubmed.ncbi.nlm.nih.gov'
        ]
        
        return any(auth in domain for auth in authoritative)
    except:
        return False

def calculate_relevance(url, claim_data):
    """
    Score how likely this URL is the actual source
    based on domain authority + entity matching
    """
    score = 0.5  # baseline
    
    # Boost if mentioned source appears in URL
    mentioned_source = claim_data.get('mentioned_source')
    if mentioned_source:
        source_slug = mentioned_source.lower().replace(' ', '')
        if source_slug in url.lower():
            score += 0.3
    
    # Boost for authoritative domains
    if '.gov' in url:
        score += 0.2
    elif '.edu' in url:
        score += 0.15
    
    return min(score, 1.0)
